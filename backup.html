<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <title>ricky herrera</title>
  <link rel="stylesheet" href="webgl.css" type="text/css">
</head>

<link href="v3.css" rel="stylesheet">

<script>
    function openC0(evt, cityName) {
        // Declare all variables
        var i, tabcontent, tablinks;

        // Get all elements with class="tabcontent" and hide them
        tabcontent = document.getElementsByClassName("tacontent");
        for (i = 0; i < tabcontent.length; i++) {
            tabcontent[i].style.display = "none";
        }


        // Get all elements with class="tablinks" and remove the class "active"
        tablinks = document.getElementsByClassName("txlinks");
        for (i = 0; i < tablinks.length; i++) {
            tablinks[i].className = tablinks[i].className.replace(" active", "");
        }

        // Show the current tab, and add an "active" class to the link that opened the tab
        document.getElementById(cityName).style.display = "block";
        evt.currentTarget.className += " active";
    }
    function openD(evt, cityName) {
        // Declare all variables
        var i, tabc, tabl;

        // Get all elements with class="tabcontent" and hide them
        tabc = document.getElementsByClassName("tabc");
        for (i = 0; i < tabc.length; i++) {
            tabc[i].style.display = "none";
        }
        tabc = document.getElementsByClassName("tacontent");
        for (i = 0; i < tabc.length; i++) {
            tabc[i].style.display = "none";
        }

        // Get all elements with class="tablinks" and remove the class "active"
        tabl = document.getElementsByClassName("tabl");
        for (i = 0; i < tabl.length; i++) {
            tabl[i].className = tabl[i].className.replace(" active", "");
        }

        // Show the current tab, and add an "active" class to the link that opened the tab
        document.getElementById(cityName).style.display = "block";
        evt.currentTarget.className += " active";
    }
    function openP(evt, cityName) {
        // Declare all variables
        var i, spp, tablp;

        // Get all elements with class="tabcontent" and hide them
        spp = document.getElementsByClassName("spp");
        for (i = 0; i < spp.length; i++) {
            spp[i].style.display = "none";
        }


        // Get all elements with class="tablinks" and remove the class "active"
        tablp = document.getElementsByClassName("tablp");
        for (i = 0; i < tablp.length; i++) {
            tablp[i].className = tablp[i].className.replace(" active", "");
        }

        // Show the current tab, and add an "active" class to the link that opened the tab
        document.getElementById(cityName).style.display = "block";
        evt.currentTarget.className += " active";
    }
    function openM(evt, cityName) {
        // Declare all variables
        var i, mrd, tabmr;

        // Get all elements with class="tabcontent" and hide them
        mrd = document.getElementsByClassName("mrd");
        for (i = 0; i < mrd.length; i++) {
            mrd[i].style.display = "none";
        }


        // Get all elements with class="tablinks" and remove the class "active"
        tabmr = document.getElementsByClassName("tabmr");
        for (i = 0; i < tabmr.length; i++) {
            tabmr[i].className = tabmr[i].className.replace(" active", "");
        }

        // Show the current tab, and add an "active" class to the link that opened the tab
        document.getElementById(cityName).style.display = "block";
        evt.currentTarget.className += " active";
    }
    function openS(evt, cityName) {
        // Declare all variables
        var i, p_section, s_tab;

        // Get all elements with class="tabcontent" and hide them
        p_section = document.getElementsByClassName("p_section");
        for (i = 0; i < p_section.length; i++) {
            p_section[i].style.display = "none";
        }


        // Get all elements with class="tablinks" and remove the class "active"
        s_tab = document.getElementsByClassName("s_tab");
        for (i = 0; i < s_tab.length; i++) {
            s_tab[i].className = s_tab[i].className.replace(" active", "");
        }

        // Show the current tab, and add an "active" class to the link that opened the tab
        document.getElementById(cityName).style.display = "block";
        evt.currentTarget.className += " active";
    }
</script>

<body onload="start();">

  <div id="mainBody">
    <div id="col1" style="float:left; margin:0; width:240px; padding-top:10%;">
      <mainHead>
        Ricky Herrera
      </mainHead>

      <div style="background-color: #000000; margin: 0 ;width: 240px;height: 1px">
      </div>

      <script type="text/javascript" src="v3.js">

      </script>


      <div class="tab">
              <button class="tablinks" onclick="openC(event, 'about')" id="dO">about</button>
              <script>
                  document.getElementById("dO").click();
                </script>
              <button class="tablinks" onclick="openC(event, 'blog')">blog</button>
              <button class="tablinks" onclick="openC(event, 'projects')">projects</button>
              <button class="tablinks" onclick="openC(event, 'films')">films</button>
              <button class="tablinks" onclick="openC(event, 'notes')">notes</button>
              <button class="tablinks" onclick="openC(event, 'pt')"  >PT</button>

              
      </div>

      <div style="background-color: #e81f55; margin: 0 ;width: 239px;height: 1px;">
      </div>

      <div id="col1">
                <div id="aboot" class="tabcontent" style="text-align:justify; width: 235px;margin:0px ;padding-top: 40px;">
                  Technically, it's Ricardo, but its <i>whutever</i>. I'm a student at UC Berkeley studying Computer Science and
                  Film Studies. I have a deep passion for computer graphics, movies, and art. <br>
                </div>

                  <div id="projz" class="tabcontent" style="width: 250px;margin:0px ;padding-top: 20px;">
                
                          <img src="p0.png" width="200">
                  
                  </div>




                  <div id="filmz" class="tabcontent" style="width: 250px;margin:0px ;padding-top: 40px;padding-left:0px;">
                      <img src="filmz.png" width="200"><br ><p><br />
                      <center>
                          - Sweet Victory<br>
                          - Walden <br>
                          - Only Love <br>
                          - The Loop <br>
                      </center>

                      
                      </div>

                  <div id="ptz" class="tabcontent" style="width: 250px;margin:0px ;padding-top: 40px;padding-left:0px;">
                          
                              - Overview<br>
                              - Ray Generation & Intersection <br>
                              - Bounding Volume Hierarchy <br>
                              - Direct Illumination <br>
                              - Indirect Illumination <br>
                              - Adaptive Sampling <br>
                              - Mirror & Glass Material <br>
                              - Microfacet Material <br>
                              - Environment Light <br>
                              - Depth of Field  <br>
    
                          
                          </div>
      </div>

    </div>

    <div id="col2" style="float:right; width:550px; ;padding-right: 2%;">

      <div id="about" class="tabcontent" style="padding-top:15%">
          <canvas id="glcanvas" width="540" height="304"></canvas><br>
      </div>

      <div id="blog" class="tabcontent">
        <mainHead>BLOG</mainHead>

        <p>blog is not available at the moment, however here are some tweets.</p>
        <a class="twitter-timeline" data-lang="en" data-width="540" data-height="600" data-theme="light" data-link-color="#E81f55"
          href="https://twitter.com/nutritiousbig">Tweets by nutritiousbig</a>
        <script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
      </div>

      <div id="projects" class="tabcontent">
        <mainHead>PROJECTS</mainHead><br/>

        <img src="p1.png" style="width:100px;padding-right:2%;" align="left"><br />
        <a href="p1website/index.html">Rasterizer</a> - C++ implemented image rasterizer – performs supersampling, hierarchical
        transforms, and texture mapping with antialiasing on SVG files and converts to 2D image. <br/><br><br>
        
          <img src="icon_meshedit.png" style="width:100px;padding-right:2%;" align="left"><br />
          <a href="p2website/index.html">MeshEdit</a> - C++ implemented 3D model mesh application; load and edit basic COLLADA
          mesh files (used by many major modeling packages and real time graphics engines).<br/><br><br>
          
            <img src="icon_pathtracer.png" style="width:100px;padding-right:2%;" align="left"><br />
            <a href="p3website/index.html">PathTracer</a> - C++ implemented, based on Physically Based Rendering (Pharr &
            Humphries) <br/><br><br>

            <img src="eminorweb/images/patologo.png" style="width:100px;padding-right:2%;" align="left"><br />
            <a href="eminorweb/index.html">E-Minor Engine </a> - OpenGL simulator, supports textures, model loading, gameplay, and lighting. <br/><br>

              
              
      </div>

      <div id="notes" class="tabcontent">
        <mainHead>
          NOTES</mainHead><br> Here are some notes I have done for UC Berkeley's CS184 Computer Graphics and Imaging course.
        (I am currently typing up some of the notes. these are really crude and do not have proper citation at the moment).
        <br>
        <div class="tabn">
                  <button class="notetab" onclick="openT(event, 'rastr')">Rasterization</button> (pdf version) <br>
                  <notesec>- Rasterization<br>
                    <notesec>- Transforms & Projection<br>
                      <notesec>- Texture Mapping<br>
                        <notesec>- Visibility, Shading, Overall Pipeline<br>
                  <button class="notetab" onclick="openT(event, 'geom')">Geometry for Graphics</button> <br>
                  <notesec>- Introduction to Geometry and Splines<br>
                    <notesec>- Bezier Curves and Surfaces<br>
                      <notesec>- Mesh Representation & Geometry <br>
                        <notesec>- Geometry Processing<br>
                  <button class="notetab" onclick="openT(event, 'light')">Lighting and Materials</button> (pdf version) <br>
                  <notesec>- Introduction to ray tracing<br>
                    <notesec>- Radiometry and Photometry<br>
                      <notesec>- Monte Carlo Integration <br>
                        <notesec>- Global Illumination<br>
                          <notesec>- Material Modeling <br>
                  <button class="notetab" onclick="openT(event, 'cam')">Camera and Lenses</button>
                  <br>
                  <br>
        </div>
      </div>
      <div id="light" class="tabcontent">
        <h1>3.1 – Introduction to Ray Tracing</h1>
Ray tracing is a technique for rendering images by following the path of a ray of light and simulating the effects of its interaction with objects in a 3D scene. The resulting rendered image is realistic, since it follows a physically based model in which light interacts with objects in the physical world. 
Consider a ray of light as a stream of photons. This ray propagates through space until it hits a surface, which interrupts the stream. The surface either absorbs, reflects, or refracts the ray. For our purposes, light travels in straight lines. Light rays do not interfere with each other if they do happen to cross. Light rays travel from light sources to the eye. 
<br>
<i>An early attempt at ray tracing was done by Arthur Appel in 1968 with ray casting. The main idea behind ray casting is that for each pixel, trace a ray from the eye (camera) through that pixel, and find the first object that intersects with that ray. The material properties of the intersected surface determine the effect of the light in the scene, and then determine the shading of this object.
</i><br>
Recursive ray tracing is also possible. A ray of light can affect more than one surface; it can bounce off or even go through other surfaces in a scene. The value of this solution is more apparent for surfaces such as metal or glass.  
A ray is defined by its origin position o, t time (with range [0, ), and a unit direction vector d. It follows that this is the ray equation (in parametric form): 
<br>
Thus, r is a function of a time t giving the point along a ray. In order for this ray to interact with a scene, this ray needs to hit faces of object. Each face can be represented by a plane, which in a 3D space is defined by a normal vector and a point on that plane. Consider the equation for a plane:
<br>
where p’ is any point on the plane and N is the normal vector. 
Now we can set up the intersection. 
<br>
<!--

Class Ray {
    vec3d o; // origin
    vec3d c: // direction

    Ray (vec3d origin, vec3d direction){
        o = origin, d = direction;
    }
};

int main() {
    cons int W = 500;
    cons int H = 500;

    for (int y = 0; y < H; y++){
        for (int x = 0; x < W; x++){
	      Ray ray( vec3d(x,y,0), vec3d(0,0,1));
	
    If ray intersects with object:
        Draw that pixel according to object surface
			
  }
    }
}-->
<h2>Accelerating Ray-Surface Intersection</h2><br>
Now that intersections are possible, there is a way to optimize the process. It would be naïve to run the algorithm #pixels x #objects times. One way to avoid this is to use bounding volumes which basically binds a complex object with a simple box volume. The object will be fully contained within this box volume, and it follows that if the ray does not hit this box volume, it will not hit our complex object. 
There are 6 potential sides that a ray could hit our box volume. 
<br>
<h1>3.2 - Radiometry and Photometry – The Physics of Light</h1>
<h2>3.2.0 – Overview</h2>
In order to achieve physically based rendering, we need to adopt a framework based in physical properties of light. Radiometry provides a measurement system and units for illumination. It allows for the measure of the spatial properties of light. It follows that this will allow us to perform light calculations in a physically correct manner. 
What is light? In the real world sense, light is created by a physical process that converts energy into photons. Each photon carries a small amount of energy. Over some time, light consumes some amount of energy, Joules. Some is turned into heat, some into photons. Exposure, is the enrgy of photons hitting an object (film, sensors, sunburn, solar panels, etc.). In computer graphics, we basically assume a “steady state” of flow, that is the rate of energy consumption is constant, so flux (powere) and energy are often interchangeable. 
<h2>3.2.1 – Foundations</h2>
<br>
Before being able to solve the rendering equation, a few foundational units and concepts shall be reviewed. A reader familiar with the material can skip this section. 
An angle of a circle is the ratio of the subtended arc length  to radius :
A solid angle  of a sphere is the ratio of the subtended area  to radius squared : 
<br>
A solid angle is a 2-dimensional angle in 3-dimesional space that a object subtends at a point. It is a measure of how large an object appears to an observer at that point. 
The unit we are most interested in solving the rendering equation are differential solid angles. 
<br>




The direction vector is .
To be isotropic is to have the have the physical property that has the same value when measured in different directions. So an Isotropic Point source is a point that emits light in all directions equally. 
<br>
<h2>3.2.1 – Irradiance and Radiance</h2>
<br>
Irradiance (illuminance) is the power per unit area incident on a surface point. 
<br>
Radiance is the fundamental field quantity that describes the distribution of light in an environment. Radiance is the quantity associated with a ray. Rendering is all about computing radiance. Radiance is invariant along a ray in a vacuum. 
<br>
<h2>3.2.1 – Irradiance and Radiance<h2>

<h1>3.3 - Monte Carlo Integration </h1><br>
The following is text from another textbook, simply for fluff, and design process. Although the cursor will never fall off the left end, it will often wander off the right end of the string. In this case we think that the cursor scans a U, which of course may be overwritten immediately. This is how the string becomes longer-a necessary feature, if we wish our machines to perform general computation. The string never becomes shorter.
Since 8 is a completely specified function, and the cursor never falls off the left end, there is only one reason why the machine cannot continue: One of the three halting states h, "yes", and "no" has been reached. If this happens, we say that the machine has halted. Furthermore, if state "yes" has been reached, we say the machine accepts its input; if "no" has been reached, then it rejects its input. If a machine halts on input x, we can define the output of the machine M on x, denoted M(x). If M accepts or rejects x, then M(x) = "yes" or "no", respectively. Otherwise, if h was reached, then the output is the string of M at the time of halting. Since the computation has gone on for finitely many steps, the string consists of at>, followed by a finite stringy, whose last symbol is not aU, possibly followed by a string-of Us (y could be empty). We consider stringy to be the output of the computation, and write M(x) = y. Naturally, it is possible that M will never halt on input x. If this is the case we write M(x) =/.
<br>
<h1>3.4 - Global Illumination</h1><br>
Fluff - - It is amazing how little we need to have everything! Viewed as a programming language, the Turing machine has a single data structure, and rather primitive one at that: A string of symbols. The available operations allow the program to move a cursor left and right on the string, to write on the current position, and to branch depending on the value of the current symbol. All in all, it is an extremely weak and primitive language. And yet, we shall argue in this chap- ter, it is capable of expressing any algorithm, of simulating any programming language.
<br>
From this initial configuration the machine takes a step according to 8, changing its state, printing a symbol, and moving the cursor; then it takes another step, and another. Note that, by our requirement on 8(p, t>), the string will always start with at>, and thus the cursor will never "fall off" the left end of the string.
<br>
<h1>3.5 - Material Modeling</h1><br>
Fluff - - It is amazing how little we need to have everything! Viewed as a programming language, the Turing machine has a single data structure, and rather primitive one at that: A string of symbols. The available operations allow the program to move a cursor left and right on the string, to write on the current position, and to branch depending on the value of the current symbol. All in all, it is an extremely weak and primitive language. And yet, we shall argue in this chap- ter, it is capable of expressing any algorithm, of simulating any programming language.




      </div>
      <div id="pt" class="tabcontent"><!-- THIS IS THE BEGINNING -->
              <div style="background-color: #222222; width: 20px;height: 1px;"></div>
              <div style="background-color: #222222; width: 20px;height: 1px; float:right;"></div>

              
              <br><br><br><br><br><br><br><br>
              <projHead>
                <center>
                  PATHTRACER
                </center>
              </projHead>
              <div id="p1_0" class="p_section" >
                  <h2>Overview</h2>
                                                  <center><img src="images/p5_ultra.png"></center><br>
  
                  How <i>do</i> 3D scenes simulate the illusion of light? One technique is pathtracing! In the virtual 3D space, there
                  are models with surface material properties, affected by direct and indirect lighting.
                  Pathtracing partitions the rendering
                  equation into two parts: direct and indirect illumination.
                                                  <center><img src="renderequation.jpg" width="450px" /></center>
  
                  <br>
                  In english, the outgoing radiance is equal to emitted radiance plus the integral over the hemisphere of the incoming radiance multiplied by the BRDF and a cosine factor.<br><br>
                  This recursively describes the propogration of light in a scene. For each bounce of light, the interaction is computed based on the BRDF. That is, for direct illumination (only one bounce of light) - sample the light and calculate that
                  light sample's contribution to the shading at some point. Indirect illumination (more than one bounce of light) goes beyond that; sample the BRDF of the first bounce
                  to another location in the scene (thus leading to a new intersections). It is at these new intersections we repeat these recursive computations until we meet some termination.<br>
  
                  <br>I know what you're thinking, <i>"but Ricky, isnt this computationally expensive?"</i> Why yes it is, but there are plenty of optimizations. Consider the bounding volume hierarchies structure that contain bounding boxes. these structures are taken advantage of in order to optimize render calculations. Different Monte Carlo sampling techniques also lead to faster render times. <br>
  <br>
                  <b>From a high level, this is what the code does:</b><br>
                  1) A 3D collada file is parsed.<br>
                  2) The Pathtracer GUI is created, providing OpenGL scene information.<br>
                  3) Once the GUI takes input (number of samples, focal distance, ..), the scene is partitioned with BVHs, preparing for the rendering process.<br>
                  4) The scene is divided into tiles. They are then put into a queue. <br>
                  5) A thread processes a tile from the queue. For every pixel in a tile, the pathtracing starts the <i> actual</i> rendering. <br>
                      <br>As tough as this project was, I thouroughly enjoyed learning the material,
                      so I purchased a copy of the book Physically Based Rendering (Pharr and Humphreys), which I also referenced.
  
  
              </div>
  
  
              <div id="p1_1" class="p_section">
                  <h2>Part 1: Ray Generation and Intersection</h2>
  
                      We want to represent rays of light, and their interactions with a given scene.
                      To begin, we want to construct a way for these rays to interact in a scene, but not necessarily compute physically based shading. <br><br>
                      <div align="center">
                          <table style="width=100%">
                              <tr>
  
                                  <img src="images/p1_1.png" width="450px" >
                                  <figcaption align="middle">woah how is this possible? keep reading and find out!</figcaption>
  
                              </tr>
                          </table>
                      </div>
  
                      Consider the Spectrum class; consisting of floats r, g, and b, the Spectrum class can roughly
                      represent the radiance & irradiance values by the intensity of each visible spectrum. I say "roughly"
                      since it is not strictly an actual spectrum with all wavelengths.
                          PathTracer::raytrace_pixel(x,y) - this function returns a Spectrum corresponding to the integral of the irradiance over the
                          pixel space coordinate (x,y), which is estimated by averaging over ns_aa samples (number of camera
                          rays in one pixel along one axis). These samples are created with the camera's generate_ray fucntion.
  
                          Camera::generate_ray(x,y) - given a 2D (X,Y) coordinate, will generate a ray from camera space to
                              world space. It is important to make sure the ray mapping is normalized since the camera has
                              its own coordinate system. That is, in camera space the camera is positioned at the origin, looks
                              along the -z axis, has the +y axis as image space "up". So consider hFov and vFov, the horizontal
                              and vertical field of view angles. With these fov's, a sensor plane can be defined one unit along
                              the camera's view direction; the bottom left and top right corners at the coordinates (-tan(radians(hFov)*.5),
                              -tan(radians(vFov)*.5),-1) = (0,0) and similarly topRight = ( tan(radians(hFov)*.5), tan(radians(vFov)*.5),-1)
                              = (1,1). The original X,Y coordinate is properly interpolating on this new plane. It should then
                              be transformed from camera to world space via a matrix transform.
  
                          Now that the creation and averaging of these camera rays are possible, lets have them interact
                          with a virtual scene. In order to accomplish triangle intersection, the Moller Trumbore ray triangle
                          intersection algorithm is sought. This calculates the intersection of a ray + triangle.
  
                          <div align="center">
                              <table style="width=100%">
                                  <tr>
                                      <td align="middle">
                                          <img src="images/slide_060.jpg" width="450px" />
                                          <figcaption align="middle">Moller Trumbore in diagram form.</figcaption>
                                  </tr>
                              </table>
                          </div>
                          <p>
                              M.T. takes advantage of the fact that triangles belong to a single plane. With barycentric coordinates, if a ray intersects
                              with a triangle, it will do so at one or between two points of the triangle, and in turn it can
                              find a point P on the triangle. </p>
                          <div align="center">
                              <table style="width=100%">
                                  <tr>
                                      <td>
                                          <img src="images/p2_1.png" width="350px" />
                                          <figcaption align="middle"></figcaption>
                                      </td>
                                      <td>
                                          <img src="images/p2_2.png" width="350px" />
                                          <figcaption align="middle"></figcaption>
                                      </td>
                                  </tr>
  
                              </table>
                          </div>
                          Hooray, we have accurate light rays that can intersect with models. Not so physically based yet though are we? For the moment. (lets try to figure out optimization for ray generation)
              </div>
  
              <div id="p1_2" class="p_section">
                  <h2>Part 2: Bounding Volume Hierarchy</h2>
                  <p>Using uniform grids in order to seperate primitive and to determine where a ray will intersect can be quite
                      inefficeint. Fortunately BVH (bounding volume hierarchies) can prevent the "Teapot in a Stadium"" problem
                      that arises from using uniform grids. These non-uniform spatial partitions are a much smarter way to
                      store information about the location of these primitives. It is necessary to go through all of the primitives
                      and determine if the current batch fit the max_leaf_size. Otherwise we would want to recurse, in order
                      to properly split the primitives. So a threshold must be generated. From the bbox's extent, which every
                      axis has the highest value will be the axis we choose. Then the axis value of the centroid box's serves
                      as a threshold. Depending on how the axis values of the other primitives related to the threshold (less
                      than or greater than), they will either be put on the left or right list. This is essentialy how the
                      recursion works.
                  </p>
                  <p>With the newly constructed BVH tree, more efficient intersections are possible. First, it determines if a
                      ray has intersected the bounding box of the current node. In the case that it doesnt, it follows that
                      the ray will not intersect with any of the primitives of the BVH. Early termination is possible! Otherwise,
                      each of its primitives needs to be checked in order to retrieve the closest intersection and return true
                      if we have hit anything at all. If the node that was being checked is not a leaf, recurse through its
                      left and right children and determine if there is a hit. </p>
                  <div align="center">
                      <table style="width=100%">
  
                          <tr>
                              <td>
                                  <img src="images/p2_3.png" width="350px" />
                                  <figcaption align="middle"></figcaption>
                              </td>
                              <td>
                                  <img src="images/p2_4.png" width="350px" />
                                  <figcaption align="middle"></figcaption>
                              </td>
                          </tr>
                          </tr>
                          <tr>
                              <td>
                                  <img src="images/p2_6.png" width="350px" />
                                  <figcaption align="middle"></figcaption>
                              </td>
                              <td>
                                  <img src="images/pt2_7.png" width="350px" />
                                  <figcaption align="middle"></figcaption>
                              </td>
                          </tr>
                      </table>
                  </div>
                  Moving beyond just triangles and spheres, smarter calculations for rays are possible now! I think its time to move onto trying
                  to make real surfaces!!!
              </div>
  
              <div id="p1_3" class="p_section">
                  <h2>Part 3: Direct Illumination</h2>
  
                  The surface of a 3D model can have properties of physical surfaces.
                  For example, a <b>diffuse </b>material is one that spreads lights equally in all directions (this is not common
                  in the physical world, but a close approximation are chalk boards and matte paint).
                  In addition to diffuse material, <b>glossy specular</b> and <b>perfect specular</b> are also common surface types. These materials are accomplished with
                  BSDFs (bidirectional scattering distribution function), an umbrella term for BRDFs and BRTFs. These are mathematical descriptions of light sccattering properties of surfaces (Veach).
                  <br>
                  <br>The path tracer now has a physically based material to render, but that means nothing if direct illumination
                      is not possible. estimate_direct_lighting emulates the effect of a direct light on a particular surface
                      (diffuse in this case). This function calculates an estimate of the direct lighting on a point hit by
                      a ray. The function sums over all of the light sources, taking samples from the surface of each light,
                      computing the incoming radiance from those sampled directions. It then converts those to outgoing radiance
                      using the BSDF at the surface.
                      <br>
                      <br>
                          If the light is a delta light, only one sample would need to be taken, otherwise there would be ns_area_light samples. A call
                          to sample_L finds the point of contact, returning the radiance, the wi direction, distToLight point
                          of contact (hit_p), and pdf (probability density function) that was calculated with wi. Now for every
                          light sample, the wi direction returned by the sample is in world space, but in order for it to be
                          passed into the BSDF it needs to be in object space (i.e. w20*wi). Now that the coordinate is in
                          object space, it needs to be ensured that it is not negative, which in that case it means the point
                          lies behind the surface. A shadow is casted to determine if it intersect with BVH. If it does not
                          intersect the irradiance of the light is calculated along with the BSDF and then divided by the PDF
                          to reduce bias.
                      <br>
  
                      <br>
                      <p> The following bunnies have only 1 sample per pixel, but a varying amount of light samples.
                          <div align="center">
                              <div id="wow1" class="tacontent" id="defaultOpen">
                                  <img src="images/wow1.png" width="500px" />
                                  <figcaption align="middle">1 light ray</figcaption>
                              </div>
  
                              <div id="wow4" class="tacontent">
                                  <img src="images/wow4.png" width="500px" />
                                  <figcaption align="middle">4 light rays</figcaption>
                              </div>
                              <div id="wow16" class="tacontent">
                                  <img src="images/wow16.png" width="500px" />
                                  <figcaption align="middle">16 light rays</figcaption>
                              </div>
                              <div id="wow64" class="tacontent">
                                  <img src="images/wow64.png" width="500px" />
                                  <figcaption align="middle">64 light rays</figcaption>
                              </div>
                          </div>

                          <div class="tab" align="center">
  
                              <button class="tlinks" onclick="openC0(event, 'wow1')" id="defaultOpen">1 Light Ray</button>
                              <script>
                                  // Get the element with id="defaultOpen" and click on it
                                  document.getElementById("defaultOpen").click();
                              </script>
                              <button class="tlinks" onclick="openC0(event, 'wow4')">4 Light Rays</button>
                              <button class="tlinks" onclick="openC0(event, 'wow16')">16 Light Rays</button>
                              <button class="tlinks" onclick="openC0(event, 'wow64')">64 Light Rays</button>
                          </div>
                          <br> Consider a scene with 64 image samples and 1 light sample. Now consider the same scene with
                          1 image sample and 64 light samples. The latter will be noisier, however only in some regions. Why
                          is that? Only one image sample is not enough for geometry that that is smaller than a pixel (sub
                          pixel features). Wont be as noisy since we sampled the light enough. A good compromise is a scene
                          sampled with 8 image samples and 8 light samples. Its much master than the first setting proposed
                          since the intersection calulation for image samples can be terminated once a target is hit, wheras
                          light samples could benefit from more samples.
              </div>
  
  
              <div id="p1_4" class="p_section">
                  <h2>Part 4: Indirect Illumination</h2>
                  <p>The start of estimate_indirect_lighting is similar to that of ‘direct’. ‘Russian roulette’ is used to determine
                      the BSDF on the surface, and to determine which samples are to be discarded. The probability is multiplied
                      by 11 and then added 0.049 to make sure the rays weren't cut off too short / cut off prematurely. The
                      probability should have a value between 0 and 1. For more randomness, a coin flip function takes in the
                      ray probability and determines if it should cast a shadow. Now, the origin of the shadow ray is offset
                      by EPS_D to make sure that the same region of light is not sampled more than it should. trace_ray is
                      used to recursively trace this ray, forming an approximation for its incoming radiance. The includeLe
                      parameter is set to isect.bsdf->is_delta() since emission is not included in the direct lighting calculation
                      for delta BSDFs. This incoming radiance is converted into an outgoing radiance estimator; it is scaled
                      by the BSDF and a cosine factor, then divided by the BSDF pdf and one minus the Russian roulette termination
                      probability. It was a little upsetting trying to get the indirect lighting to show up when I forgot to
                      set the depth of a ray to the max_ray_depth (that prevented the actual indirect light from showing up).
                  </p>
  
                  <div align="center">
                      <div id="depth0" class="tabc" id="defape">
                          <img src="images/spheres4.png" width="500px" />
                          <figcaption align="middle">max ray depth 0</figcaption>
                      </div>
                      <div id="depth1" class="tabc">
                          <img src="images/spheres3.png" width="500px" />
                          <figcaption align="middle">max ray depth 1</figcaption>
                      </div>
                      <div id="depth2" class="tabc">
                          <img src="images/spheres2.png" width="500px" />
                          <figcaption align="middle">max ray depth 2</figcaption>
                      </div>
                      <div id="depth3" class="tabc">
                          <img src="images/spheres1.png" width="500px" />
                          <figcaption align="middle">max ray depth 3</figcaption>
                      </div>
                      <div id="depth100" class="tabc">
                          <img src="images/spheres.png" width="500px" />
                          <figcaption align="middle">max ray depth 100</figcaption>
                      </div>
                  </div>
                  <div class="tab" align="center">
                      <button class="tabl" onclick="openD(event, 'depth0')" id="defape">depth 0</button>
                      <script>
                                          // Get the element with id="defaultOpen" and click on it
                                          document.getElementById("defape").click();
                      </script>
                      <button class="tabl" onclick="openD(event, 'depth1')">depth 1</button>
                      <button class="tabl" onclick="openD(event, 'depth2')">depth 2</button>
                      <button class="tabl" onclick="openD(event, 'depth3')">depth 3</button>
                      <button class="tabl" onclick="openD(event, 'depth100')">depth 100</button>
                  </div>
                  <br>
                  <br>
                  <div align="center">
                      <div id="1spp" class="spp">
                          <img src="images/part4del/p4spheres1.png" width="500px" />
                          <figcaption align="middle">1 sample per pixel</figcaption>
                      </div>
                      <div id="2spp" class="spp">
                          <img src="images/part4del/p4spheres2.png" width="500px" />
                          <figcaption align="middle">2 samples per pixel</figcaption>
                      </div>
                      <div id="4spp" class="spp">
                          <img src="images/part4del/p4spheres4.png" width="500px" />
                          <figcaption align="middle">4 samples per pixel</figcaption>
                      </div>
                      <div id="8spp" class="spp">
                          <img src="images/part4del/p4spheres8.png" width="500px" />
                          <figcaption align="middle">8 samples per pixel</figcaption>
                      </div>
                      <div id="16spp" class="spp">
                          <img src="images/part4del/p4spheres16.png" width="500px" />
                          <figcaption align="middle">16 samples per pixel</figcaption>
                      </div>
                      <div id="64spp" class="spp">
                          <img src="images/part4del/p4spheres64.png" width="500px" />
                          <figcaption align="middle">64 samples per pixel</figcaption>
                      </div>
  
                      <div id="1024spp" class="spp">
                          <img src="images/part4del/1024spheres.png" width="500px" />
                          <figcaption align="middle">1024 samples per pixel</figcaption>
                      </div>
  
                  </div>
                  <div class="tab" align="center">
                      <button class="tablp" onclick="openP(event, '1spp')" id="defspp">1 spp</button>
                      <script>
                                              // Get the element with id="defaultOpen" and click on it
                                              document.getElementById("defspp").click();
                      </script>
                      <button class="tablp" onclick="openP(event, '2spp')">2 spp</button>
                      <button class="tablp" onclick="openP(event, '4spp')">4 spp</button>
                      <button class="tablp" onclick="openP(event, '8spp')">8 spp</button>
                      <button class="tablp" onclick="openP(event, '16spp')">16 spp</button>
                      <button class="tablp" onclick="openP(event, '64spp')">64 spp</button>
                      <button class="tablp" onclick="openP(event, '1024spp')">1024 spp</button>
                  </div>
                  <br>
                  <div align="center">
                      <table style="width=100%">
                          <tr>
                              <td>
                                  <img src="images/p4_u.png" width="350px" />
                                  <figcaption align="middle">only indirect light</figcaption>
                              </td>
                              <td>
                                  <img src="images/p4_only_direct.png" width="350px" />
                                  <figcaption align="middle">only direct light</figcaption>
                              </td>
                          </tr>
  
                      </table>
                  </div>
              </div>
              <div id="p1_5" class="p_section">
                  <h2>Part 5: Adaptive Sampling</h2>
                  <p> An increase in the number of samples results in less noise (the wonders of higher frequency rates :] ). It
                      follows that this improved rate will increase the render time. But of course there are solutions; adaptive
                      sampling allows a reduction in noise, while still being more effecient than just an unoptimized increase
                      in samples. The key is to focus on samples in select parts of the scene, those that end up being more
                      difficult. This implementation determines if the illuminance of a pixel converges. Namely, the mean and
                      the variance are calculated for calculation (light illuminance and light illuminance squared).
                      <p>
                          Red and blue colors represent high and low sampling rates. Sampling rates are computed as the ratio between the actual number
                          of samples and the maximum number of samples allowed.
                          <p> If a pixel has reached a point where its average illuminance is bounded by some tolerance of its
                              expected illuminance, then it does not need to trace more rays. One frustrating part, while rendering
                              on my (weak) computer, the rate would only come out as a solid color. This was due to rendering
                              at a low rate. This low rate prevented a higher concentration of sampled in the ~difficult areas
                              of the scene. But luckily, using the strong lab computers and setting up a high sample render
                              ensured the implementation was working.
                          </p>
                          <div align="center">
                              <table style="width=100%">
                                  <tr>
                                      <td>
                                          <img src="images/pt5_bunny.png" width="350px" />
                                          <figcaption align="middle">1028 samples per pixel</figcaption>
                                      </td>
                                      <td>
                                          <img src="images/pt5_bunny_rate.png" width="350px" />
                                          <figcaption align="middle">corresponding rate</figcaption>
                                      </td>
                                  </tr>
                                  <tr>
                                      <td>
                                          <img src="images/p5_ultra.png" width="350px" />
                                          <figcaption align="middle">2048 samples per pixel</figcaption>
                                      </td>
                                      <td>
                                          <img src="images/p5_ultra_rate.png" width="350px" />
                                          <figcaption align="middle">corresponding rate</figcaption>
                                      </td>
                                  </tr>
                              </table>
                          </div>
              </div>
  
  
              <p>
                  <p>
                      <div id="p2_1" class="p_section" >
                      <h2>Second Half of project - Overview</h2>
                      <p>DISCLAIMER: the write up portion of this half of the project is still in the works.
                          <p> This section concludes the pathtracer project, a basic but effectice ray tracer. First mirror and
                              glass material surfaces were accomplished. I can't look at glass in real life the same way anymore.
                              Then microfacet material, which work by statistically modeling light from a bigger collection
                              of microfacets (PBRT). And then an attempt at hollywood magic was done by creating environment
                              lights, which basically means taking exr images and having them in a sense project in the background
                              of a scene, and serve as light sources that can interact with the surfaces on the model (probably
                              the most challenging portion of this endeavor). And finally a ray tracer would not be complete
                              without the ability to play with depth of field. This portion made me forget my final renders
                              were derived from 3D models as opposed to an actual image of a real life dragon in a cubic room.
                              Overall this was a really informative project, and what I got in the end was a new appreciation
                              for light and computer graphics as a whole. I would not have finished this without referenceing
                              Physically Based Rendering. </p>
  
                          <h2>Part 1: Mirror and Glass Materials</h2>
                          Physically based rendering would not be complete without emulating the way light reflects and refracts on mirror and glass
                          surfaces. In order to accomplish a mirror-like surface, it need be modeled with perfect specular
                          reflection.For examplel MirrorBSDF::f() simply returns an empty Spectrum(), as it is safe to assume
                          that a wi direction that was not created using sample_f() has no chance of being equal to the reflection
                          of wo. In order to accomplish a glass-like surface, specular reflection and transmission are at its
                          core. These are weighted by Fresnal terms (or Schlick's approximation) for accurate angular-dependent
                          variation (Pharr&Humphries). We alter the maximum ray depth with values: 0, 1, 2, 3, 4, 5, 100. Once
                          the ray depth is 3 or greater, some interesting artifacts begin to show up. The following sequence
                          have 64 samples per pixel and 4 samples per light each, as well.
                          <div align="center">
                              <div id="rd0" class="mrd">
                                  <img src="p32website/images/p1/0_sphere.png" width="445px" />
                                  <figcaption align="middle">max ray depth = 0</figcaption>
                              </div>
                              <div id="rd1" class="mrd">
                                  <img src="p32website/images/p1/1_sphere.png" width="445px" />
                                  <figcaption align="middle">max ray depth = 1</figcaption>
                              </div>
                              <div id="rd2" class="mrd">
                                  <img src="p32website/images/p1/2_sphere.png" width="445px" />
                                  <figcaption align="middle">max ray depth = 2</figcaption>
                              </div>
                              <div id="rd3" class="mrd">
                                  <img src="p32website/images/p1/3_sphere.png" width="445px" />
                                  <figcaption align="middle">max ray depth = 3 (why the white spot on floor?)</figcaption>
                              </div>
                              <div id="rd4" class="mrd">
                                  <img src="p32website/images/p1/4_sphere.png" width="445px" />
                                  <figcaption align="middle">max ray depth = 4</figcaption>
                              </div>
                              <div id="rd5" class="mrd">
                                  <img src="p32website/images/p1/5_sphere.png" width="445px" />
                                  <figcaption align="middle">max ray depth = 5</figcaption>
                              </div>
                              <div id="rd100" class="mrd">
                                  <img src="p32website/images/p1/100_sphere.png" width="445px" />
                                  <figcaption align="middle">max ray depth = 100</figcaption>
                              </div>
                          </div>
                          <div class="tab" align="center">
                              <button class="tabmr" onclick="openM(event, 'rd0')" id="rddef">0</button>
                              <script>
                                              // Get the element with id="defaultOpen" and click on it
                                              document.getElementById("rddef").click();
                              </script>
                              <button class="tabmr" onclick="openM(event, 'rd1')">1</button>
                              <button class="tabmr" onclick="openM(event, 'rd2')">2</button>
                              <button class="tabmr" onclick="openM(event, 'rd3')">3</button>
                              <button class="tabmr" onclick="openM(event, 'rd4')">4</button>
                              <button class="tabmr" onclick="openM(event, 'rd5')">5</button>
                              <button class="tabmr" onclick="openM(event, 'rd100')">100</button>
                          </div>
  
  
                          There are scenes that are difficult for path tracers. The light goes through sphere and gets concentrated and forms a disc
                          shape highlight on the floor. These are referred to as caustics. Once the scene contains caustics,
                          it become tough on the renderer. Why is that?
                          <p> Well suppose you shoot more rays into the scene that actually hit the caustics. Also consider that
                              the floor has a diffuse BRDF material. You want to sample it, according to the diffuse brdf.
                              TO get caustics, it should come from light, so it makes sense to want to intersect the ray on
                              that caustic to the sphere, however BRDF has uniform sampling, which ultimatly means there is
                              low chance of hitting out point of interest (the light source). Consider the scenes with max
                              ray depth greater than or equal to 3; these artifacts are apparent in here :( .
  
  </div>
                          <div id="p2_2" class="p_section" >
  
                              <h2>Part 2: Microfacet Material</h2>
                              This portion really made the enire physically based rendering idea hit home. At first I was struggling to understand what
                              the spec was trying to tell me, but after testing out this website (https://refractiveindex.info/?shelf=main&book=Si&page=Aspnes),
                              I realized that the physical properties of conductor material can essentially be mapped in computer
                              graphics. This was a lot to take in, as the implementation was pretty challenging. It is safe
                              to assume that rough surfaces can be modeled as a collection of microfacets. According to Pharr
                              & Humphries, surfaces made of microfacets are "essentially heightfield, where the distribution
                              is described statistically". It was trying to understand it statistically that was a bit challenging.
                              Here we alter the alpha value (0.005, 0.05, 0.25, 0.5), which is basically the roughness term.
                              <div align="center">
                                  <table style="width=100%">
                                      <tr>
                                          <td align="middle">
                                              <img src="p32website/images/p2/p2_a005r1.png" width="445px" />
                                              <figcaption align="middle">alpha = 0.005</figcaption>
                                          </td>
                                          <td>
                                              <img src="p32website/images/p2/p2_a05r.png" width="445px" />
                                              <figcaption align="middle">alpha = 0.05</figcaption>
                                          </td>
                                      </tr>
  
                                      <tr>
                                          <td>
                                              <img src="p32website/images/p2/p2_a25r0.png" width="445px" />
                                              <figcaption align="middle">alpha = 0.25</figcaption>
                                          </td>
                                          <td>
                                              <img src="p32website/images/p2/p2_a5r1.png" width="445px" />
                                              <figcaption align="middle">alpha = 0.5</figcaption>
                                          </td>
                                      </tr>
                                  </table>
                              </div>
                              <p>
                                  Here, it is evident that a hemisphere sampling approach has much more noise than that of a importance sampling approach.
                                  For both renders, there are 64 samples per pixel, 1 sample per light, and max ray depth of
                                  5. Again, the only varying factor is the sampling method.The physical properties of copper
                                  can be taken advantage of to create less noisy images, and overall replicate copper fairly
                                  realistically in CG. Importance sampling is evidently the stronger approach.
                                  <div align="center">
                                      <table style="width=100%">
                                          <tr>
                                              <td align="middle">
                                                  <img src="p32website/images/p2/p2_bunny_default6.png" width="445px" />
                                                  <figcaption align="middle">rendered using cosine hemisphere sampling </figcaption>
                                              </td>
                                              <td>
                                                  <img src="p32website/images/p2/p2_bunny_importance.png" width="445px" />
                                                  <figcaption align="middle">rendered using importance sampling </figcaption>
                                              </td>
                                          </tr>
                                      </table>
                                  </div>
  
                                  <div align="center">
                                      <table style="width=100%">
                                          <tr>
                                              <td align="middle">
                                                  <img src="p32website/images/p2/neweta.png" width="445px" />
                                                  <figcaption align="middle"></figcaption>
                                              </td>
                                          </tr>
                                      </table>
                                  </div>
                                  This was the portion I found the most interesting, because the time spent debugging made the concepts a little stronger.
                                  For a while my renders came out quite splotchy and had too many white spots all over. I realized
                                  (after a while) that perhaps I was diving by 0 while calculating the indirect light. I feel
                                  I spent a little more time than I would have wanted on this section.
  </div>
                              <div id="p2_3" class="p_section" >
                                  <h2>Part 3: Environment Light</h2>
                                  Suppose there is a need to create a scene of a forest, or cafe. As opposed to creating an entire scene with actual models
                                  in the scene, suppose we have a map that can mimic the illusion of being in that scene. That
                                  is, if we have a main mesh we want to focus on and want to place it in another low cost enviroment,
                                  we can opt for environment maps. Like adding a matte painting in post production of a film,
                                  adding an environment map can be quite effective in create a bigger world. Not only is the
                                  image map mapped out over the hemisphere of the scene, it can also create light that will
                                  bounce off meshes w/ physically based surfaces quite convincingly.
                                  <div align="center">
                                      <table style="width=100%">
                                          <tr>
                                              <td>
                                                  <img src="p32website/images/p3/probability_debug.png" width="650px" />
                                                  <figcaption align="middle">probability debug image</figcaption>
                                              </td>
                                          </tr>
                                      </table>
                                  </div>
                                  <p>
                                      Here are two renders of bunny_unlit.dae and the environment map. One was rendered with uniform sampling. The other one was
                                      rendered with importance sampling. Both images have 4 samples per pixel and 64 samples
                                      per light in each. The sampling method did not appear to make a visible difference. They
                                      are both the same in terms of level/amount of noise.
                                      <div align="center">
                                          <table style="width=100%">
                                              <tr>
                                                  <td>
                                                      <img src="p32website/images/p3/p3_uniform_bun.png" width="445px" />
                                                      <figcaption align="middle">uniform sampling</figcaption>
                                                  </td>
                                                  <td>
                                                      <img src="p32website/images/p3/p3_import_bun.png" width="445px" />
                                                      <figcaption align="middle">importance sampling</figcaption>
                                                  </td>
                                              </tr>
                                          </table>
                                      </div>
                                      <p>
                                          Similarly as the previous section, here are two renders of bunny_microfacet_cu_unlit.dae and the environment map. One was
                                          rendered with uniform sampling, one with importance sampling. Both images have 4
                                          samples per pixel and 64 samples per light in each. The noise on both surfaces look
                                          fairly similar.
                                          <div align="center">
                                              <table style="width=100%">
                                                  <tr>
                                                      <td>
                                                          <img src="p32website/images/p3/p3_microbunny_uniform.png" width="445px" />
                                                          <figcaption align="middle">uniform sampling</figcaption>
                                                      </td>
                                                      <td>
                                                          <img src="p32website/images/p3/p3_microbunny_import.png" width="445px" />
                                                          <figcaption align="middle">importance sampling</figcaption>
                                                      </td>
                                                  </tr>
                                              </table>
                                          </div>
  </div>
                                      <div id="p2_4" class="p_section" >
  
                                          <h2>Part 4: Depth of Field</h2>
                                          Depth of field is a characteristic that sells the illusion of renders having some physically based setting, or at least,
                                          they help sell the idea of these scenes being captured via a camera lens. This was
                                          a simple part to implement, however I was having a few miscalculations; when I would
                                          reorient the camera in the GUI and then render, I would recieve a completely obscure
                                          angle. This was just a matter of not normalizing and conertin world and camera points
                                          though. All of the following images were rendered with 64 samples per pixel, 4 lights
                                          per sample, max depth ray of 5. Focus Stack - here, all of the images have an apperative
                                          size of 0.03, but have varying focus depth. I'd say the one that I find most pleasing
                                          is the one with focus depth 1.5.
                                          <div align="center">
                                              <table style="width=100%">
                                                  <tr>
                                                      <td>
                                                          <img src="p32website/images/p4/p4_1_05_f.png" width="445px" />
                                                          <figcaption align="middle">focus depth of 0.5</figcaption>
                                                      </td>
                                                  </tr>
                                                  <tr>
                                                      <td align="middle">
                                                          <img src="p32website/images/p4/p4_1_10_f.png" width="445px" />
                                                          <figcaption align="middle">focus depth of 1.0</figcaption>
                                                      </td>
                                                      <td>
                                                          <img src="p32website/images/p4/p4_1_15_r.png" width="445px" />
                                                          <figcaption align="middle">focus depth of 1.5</figcaption>
                                                      </td>
                                                  </tr>
  
                                                  <tr>
                                                      <td>
                                                          <img src="p32website/images/p4/p4_1_20_r.png" width="445px" />
                                                          <figcaption align="middle">focus depth of 2.0</figcaption>
                                                      </td>
                                                      <td>
                                                          <img src="p32website/images/p4/p4_1_25_r.png" width="445px" />
                                                          <figcaption align="middle">focus depth of 2.5</figcaption>
                                                      </td>
                                                  </tr>
  
                                              </table>
                                          </div>
                                          Different Apperature sizes - the implementation of the thin lens creates the desired result/effect.
                                          <div align="center">
                                              <table style="width=100%">
  
                                                  <tr>
                                                      <td align="middle">
                                                          <img src="p32website/images/p4/p4_1_15_r.png" width="445px" />
                                                          <figcaption align="middle">aperature size 0.03</figcaption>
                                                      </td>
                                                      <td>
                                                          <img src="p32website/images/p4/p4_2_13_f.png" width="445px" />
                                                          <figcaption align="middle">aperature size 0.13</figcaption>
                                                      </td>
                                                  </tr>
                                                  <tr>
                                                      <td align="middle">
                                                          <img src="p32website/images/p4/p4_2_23_f.png" width="445px" />
                                                          <figcaption align="middle">aperature size 0.23</figcaption>
                                                      </td>
                                                      <td>
                                                          <img src="p32website/images/p4/p4_2_33_f.png" width="445px" />
                                                          <figcaption align="middle">aperature size 0.33</figcaption>
                                                      </td>
                                                  </tr>
  
                                                  <tr>
                                                      <td>
                                                          <img src="p32website/images/p4/p4_2_43_f.png" width="445px" />
                                                          <figcaption align="middle">aperature size 0.43</figcaption>
                                                      </td>
  
                                                  </tr>
                                              </table>
                                          </div>
                                          </div>
          
      </div><!-- THIS IS THE END -->


      <div id="films" class="tabcontent">
        <mainHead>
          FILMS</mainHead><br />
        <h2><i>Sweet Victory</i> (2016)</h2>
        <iframe width="540" height="304" src="https://www.youtube.com/embed/KFBjPTmTnWQ" frameborder="0" allowfullscreen></iframe><br>
        My first 3D animated short! My notable contribution to this masterpiece is Marshmallow (or as like my mom refers to it, "El
        Bombon"), which I modeled and animated. Learning Maya and other software was so rewarding, and this project helped me explore some of their capabilites. Fun fact: the chocolate fountain was for a time a bifrost simulation with very viscous chocolate. However, the renderfarm hates us and it didn't go as planned. This was made during my semester of UCBUGG, probably the best class I have taken while at Berkeley. 

        <br>
        <h2><i>Walden</i> (2016) </h2>
        <iframe width="540" height="304" src="https://www.youtube.com/embed/VXAhPhIJJVg" frameborder="0" allowfullscreen></iframe><br>
        The piece was my group's submission for Cal State Long Beach's 24 Hours Challenge; as the name implies this was made in under
        24 hours. The prompt was "make a 1 minute short that contains a physical or metaphorical wall". You learn a lot about your animation partners when trapped in a computer lab for 24 hours. We all left with a new connection with one another; and sleep deprivation. 
        <br>

          
        <h2><i>The Only Love a Mans Ever Known</i> (2017) <br /></h2>
          <iframe width="540" height="304" src="https://www.youtube.com/embed/0EiJ86TQ2_g" frameborder="0" allowfullscreen></iframe><br> 
          This project was made for UC Berkeley's Advanced Digital Animation course, CNM190 (Fall 2016 - Spring 2017). In essence, its a short about the pangs of alcoholism, but very layered, revealing new meanings with every view. I worked on the sound effects, lighting, modeling, and post-production for this short. Specifically, the lighting I am proud of is during the liquor store scene, as we experiemented with what felt like every possible variation. I am really proud of the music I wrote for this, especially when I found my peers humming the music at random times. It has won an award at the East
          LA film festival, and is being considered for other film festivals!<br >
          
          <h2><i>The Loop</i> (2017) <br /></h2>
          <iframe width="540" height="304" src="https://www.youtube.com/embed/gXxwrEiDg48" frameborder="0" allowfullscreen></iframe><br> 
          This short was made for the Campus Movie Festival @ UC Berkeley. I worked on the music, some color grading, and story ideas. (I wrote the music in 30 minutes, while waiting to get medication).<br>

          <br>
          STAY TUNED // MORE TO COME // 
        
      </div>
    </div>



  </div>

  <script>
    document.getElementById("defaultOpen").click();
  </script>

</body>

<script src="gl-matrix.js"></script>
<script src="webgl-demo.js"></script>

</html>